{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Get the default gateway IP dynamically\n",
    "try:\n",
    "    hostip = subprocess.check_output(\"ip route | grep default | awk '{print $3}'\", shell=True).decode().strip()\n",
    "    port = 7890\n",
    "    PROXY_HTTP = f\"http://{hostip}:{port}\"\n",
    "    \n",
    "    # Set proxy environment variables\n",
    "    os.environ['http_proxy'] = PROXY_HTTP\n",
    "    os.environ['https_proxy'] = PROXY_HTTP\n",
    "    print(f\"Using proxy: {PROXY_HTTP}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not set proxy: {e}\")\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"neuralwork/arxiver\")\n",
    "\n",
    "# Convert to pandas DataFrame for easier viewing\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "# Show the first 5 papers with title and abstract\n",
    "# print(df['markdown'].iloc[0])\n",
    "\n",
    "# df[['markdown']].to_csv('raw_paper_data/markdown_only.csv', index=False)\n",
    "type(df['markdown'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "separators = [\"\\n\\n\", \"\\n\", \" \", \"\", \".\"]\n",
    "\n",
    "# Get your splitter ready\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=separators, chunk_size=1000, chunk_overlap=5)\n",
    "\n",
    "# Split your docs into texts\n",
    "texts_paper = text_splitter.create_documents(df['markdown'].values)\n",
    "\n",
    "# Embeddings\n",
    "hg_embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import LanceDB\n",
    "import lancedb\n",
    "\n",
    "# Create a directory for the database if it doesn't exist\n",
    "os.makedirs(\"docs/lancedb_rag\", exist_ok=True)\n",
    "\n",
    "# Connect to a database (creates it if it doesn't exist)\n",
    "db = lancedb.connect(\"docs/lancedb_rag\")\n",
    "\n",
    "# Create a LanceDB vector store\n",
    "langchain_lancedb = LanceDB.from_documents(\n",
    "    documents=texts_paper,\n",
    "    embedding=hg_embeddings,\n",
    "    connection=db,\n",
    "    table_name=\"humanizer_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "persist_directory = 'docs/chroma_rag/'\n",
    "langchain_chroma = Chroma.from_documents(\n",
    "    documents=texts_paper,\n",
    "    collection_name=\"humanizer_data\",\n",
    "    embedding=hg_embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24869/1887491695.py:5: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  langchain_chroma = Chroma(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "hg_embeddings = HuggingFaceEmbeddings()\n",
    "persist_directory = 'docs/chroma_rag/'\n",
    "langchain_chroma = Chroma(\n",
    "    collection_name=\"humanizer_data\",\n",
    "    embedding_function=hg_embeddings,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='The algorithm performs the following steps:'),\n",
       " Document(metadata={}, page_content='**Algorithm 2** Details of the step (a) in Block 2 of the Algorithm 1'),\n",
       " Document(metadata={}, page_content='error & refinement) prompts. The details are shown in Algorithm 2.'),\n",
       " Document(metadata={}, page_content='The subsequent phases of the process iteratively flip each bit in the partition vector and update \\\\(MinCost\\\\) if the cost of the new partition vector is lower. This process is repeated until all bits have been flipped. This marks the completion of one iteration or pass through Algorithm 1. Once a pass is completed, Algorithm 1 prepares the initial partition vector for the next iteration from the partition vector with the lowest cost given by \\\\(MinCost\\\\) and the initial partition vector, then applies a crossover operation using Algorithm 4 to generate the new initial partition vector for the next pass.'),\n",
       " Document(metadata={}, page_content='Before proceeding into the description of the four algorithms, we first summarize the additional notations used throughout this section in Table 3.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain_chroma.similarity_search('The authors state \"updating the “Break List” (delta) and “Working List” (omega) in Algorithm 1', k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
